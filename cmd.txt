
# 启动 HDFS 和 YARN -- 主要包括 NameNode DataNode NodeManager ResourceManager 进程
/usr/local/hadoop/sbin/start-dfs.sh; /usr/local/hadoop/sbin/start-yarn.sh

jps

# 查看 NameNode 相关信息
curl http://localhost:50070/

# 将本地文件系统中的xml文件导入到 hdfs，执行示例，再将结果从 hdfs 导出到本地文件系统
hdfs dfs -mkdir -p /user/hadoop
hdfs dfs -mkdir -p input
hdfs dfs -put /usr/local/hadoop/etc/hadoop/*.xml input
hdfs dfs -ls input
hdfs dfs -rm -r -f output
hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output 'dfs[a-z.]+'
hdfs dfs -cat output/*
hdfs dfs -get output /usr/local/hadoop/output
cat /usr/local/hadoop/output/*


# 启动 hive
hive
# 在 hive 控制台中执行 -- 创建表，导入本地文件系统中的数据，执行查询，结果保存在 hdfs，导出结果到本地文件系统
CREATE TABLE invites (foo INT, bar STRING) PARTITIONED BY (ds STRING);
SHOW TABLES;
DESCRIBE invites;
ALTER TABLE invites ADD COLUMNS (new_col2 INT COMMENT 'a comment');
ALTER TABLE invites REPLACE COLUMNS (foo INT, bar STRING, baz INT COMMENT 'baz replaces new_col2');
LOAD DATA LOCAL INPATH '/usr/local/hive/examples/files/kv2.txt' OVERWRITE INTO TABLE invites PARTITION (ds='2008-08-15');
LOAD DATA LOCAL INPATH '/usr/local/hive/examples/files/kv3.txt' OVERWRITE INTO TABLE invites PARTITION (ds='2008-08-08');
SELECT a.foo FROM invites a WHERE a.ds='2008-08-15';
INSERT OVERWRITE DIRECTORY '/tmp/hdfs_out' SELECT a.* FROM invites a WHERE a.ds='2008-08-15';
DROP TABLE invites;
dfs -cat /tmp/hdfs_out/*;


# 设置 hive CLI，查询时显示表的列名
echo "set hive.cli.print.header=true;" >>~/.hiverc
